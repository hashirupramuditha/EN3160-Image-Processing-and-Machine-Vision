{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import glob\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imsave\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "TRAIN_DATASET_PATH = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n",
    "\n",
    "test_image_flair = nib.load('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_flair.nii').get_fdata()\n",
    "test_image_flair = scaler.fit_transform(test_image_flair.reshape(-1, test_image_flair.shape[-1])).reshape(test_image_flair.shape)\n",
    "print(test_image_flair.max())\n",
    "\n",
    "test_image_t1 = nib.load('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_t1.nii').get_fdata()\n",
    "test_image_t1 = scaler.fit_transform(test_image_t1.reshape(-1, test_image_t1.shape[-1])).reshape(test_image_t1.shape)\n",
    "print(test_image_t1.max())\n",
    "\n",
    "test_image_t1ce = nib.load('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_t1ce.nii').get_fdata()\n",
    "test_image_t1ce = scaler.fit_transform(test_image_t1ce.reshape(-1, test_image_t1ce.shape[-1])).reshape(test_image_t1ce.shape)\n",
    "print(test_image_t1ce.max())\n",
    "\n",
    "test_image_t2 = nib.load('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_t2.nii').get_fdata()\n",
    "test_image_t2 = scaler.fit_transform(test_image_t2.reshape(-1, test_image_t2.shape[-1])).reshape(test_image_t2.shape)\n",
    "print(test_image_t2.max())\n",
    "\n",
    "test_mask = nib.load('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_seg.nii').get_fdata()\n",
    "test_mask = test_mask.astype(np.uint8)\n",
    "print(np.unique(test_mask))\n",
    "test_mask[test_mask==4] = 3\n",
    "print(np.unique(test_mask))\n",
    "\n",
    "\n",
    "import random\n",
    "n_slice = random.randint(0, test_mask.shape[2])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.imshow(test_image_flair[:, :, n_slice], cmap='gray')\n",
    "plt.title(\"Image flair\")\n",
    "plt.subplot(232)\n",
    "plt.imshow(test_image_t1[:, :, n_slice], cmap='gray')\n",
    "plt.title(\"Image t1\")\n",
    "plt.subplot(233)\n",
    "plt.imshow(test_image_t1ce[:, :, n_slice], cmap='gray')\n",
    "plt.title(\"Image t1ce\")\n",
    "plt.subplot(234)\n",
    "plt.imshow(test_image_t2[:, :, n_slice], cmap='gray')\n",
    "plt.title(\"Image t2\")\n",
    "plt.subplot(235)\n",
    "plt.imshow(test_mask[:, :, n_slice])\n",
    "plt.title(\"Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_x = np.stack([test_image_flair, test_image_t1ce, test_image_t2], axis=3)\n",
    "\n",
    "combined_x = combined_x[56:184, 56:184, 13:141]\n",
    "\n",
    "test_mask = test_mask[56:184, 56:184, 13:141]\n",
    "\n",
    "n_slice = random.randint(0, test_mask.shape[2])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(combined_x[:, :, n_slice, 0], cmap='gray')\n",
    "plt.title(\"Image flair\")\n",
    "plt.subplot(222)\n",
    "plt.imshow(combined_x[:, :, n_slice, 1], cmap='gray')\n",
    "plt.title(\"Image t1ce\")\n",
    "plt.subplot(223)\n",
    "plt.imshow(combined_x[:, :, n_slice, 2], cmap='gray')\n",
    "plt.title(\"Image t2\")\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:, :, n_slice])\n",
    "plt.title(\"Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsave('/kaggle/working/combined001.tif', combined_x)\n",
    "np.save('/kaggle/working/combined001.npy', combined_x)\n",
    "\n",
    "my_img = np.load('/kaggle/working/combined001.npy')\n",
    "combined_x == my_img.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask = to_categorical(test_mask, num_classes=4)\n",
    "\n",
    "\n",
    "t2_list = sorted(glob.glob('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*t2.nii'))\n",
    "t1ce_list = sorted(glob.glob('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*t1ce.nii'))\n",
    "flair_list = sorted(glob.glob('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*flair.nii'))\n",
    "mask_list = sorted(glob.glob('/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*seg.nii'))\n",
    "\n",
    "t2_list = t2_list[0:120]\n",
    "t1ce_list = t1ce_list[0:120]\n",
    "flair_list = flair_list[0:120]\n",
    "mask_list = mask_list[0:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# shutil.rmtree('/kaggle/working/BraTS2020_TrainingData')\n",
    "file1 = '/kaggle/working/combined001.npy'\n",
    "file2 = '/kaggle/working/combined001.tif'\n",
    "\n",
    "if os.path.exists(file1 or file2):\n",
    "    os.remove(file1)\n",
    "    os.remove(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path('/kaggle/working/BraTS2020_TrainingData/input_data_3channels/images').mkdir(parents=True, exist_ok=True)\n",
    "Path('/kaggle/working/BraTS2020_TrainingData/input_data_3channels/masks').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for img in range(len(t2_list)):\n",
    "    print(\"Now preparing image and mask number: \", img)\n",
    "    \n",
    "    temp_image_t2 = nib.load(t2_list[img]).get_fdata()\n",
    "    temp_image_t2 = scaler.fit_transform(temp_image_t2.reshape(-1, temp_image_t2.shape[-1])).reshape(temp_image_t2.shape)\n",
    "    \n",
    "    temp_image_t1ce = nib.load(t1ce_list[img]).get_fdata()\n",
    "    temp_image_t1ce = scaler.fit_transform(temp_image_t1ce.reshape(-1, temp_image_t1ce.shape[-1])).reshape(temp_image_t1ce.shape)\n",
    "    \n",
    "    temp_image_flair = nib.load(flair_list[img]).get_fdata()\n",
    "    temp_image_flair = scaler.fit_transform(temp_image_flair.reshape(-1, temp_image_flair.shape[-1])).reshape(temp_image_flair.shape)\n",
    "    \n",
    "    temp_mask = nib.load(mask_list[img]).get_fdata()\n",
    "    temp_mask = temp_mask.astype(np.uint8)\n",
    "    temp_mask[temp_mask==4] = 3\n",
    "    \n",
    "    temp_combined_images = np.stack([temp_image_flair, temp_image_t1ce, temp_image_t2], axis=3)\n",
    "    \n",
    "    \n",
    "    temp_combined_images = temp_combined_images[56:184, 56:184, 13:141]\n",
    "    temp_mask = temp_mask[56:184, 56:184, 13:141]\n",
    "    \n",
    "    val, counts = np.unique(temp_mask, return_counts=True)\n",
    "    \n",
    "    if (1 - (counts[0]/counts.sum())) > 0.01:\n",
    "        print(\"Save Me\")\n",
    "        temp_mask = to_categorical(temp_mask, num_classes=4)\n",
    "        np.save('/kaggle/working/BraTS2020_TrainingData/input_data_3channels/images/image_'+str(img)+'.npy', temp_combined_images)\n",
    "        np.save('/kaggle/working/BraTS2020_TrainingData/input_data_3channels/masks/mask_'+str(img)+'.npy', temp_mask)\n",
    "        \n",
    "    else:\n",
    "        print(\"I am useless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "!pip install split_folders\n",
    "import splitfolders  # or import split_folders\n",
    "\n",
    "input_folder = '/kaggle/working/BraTS2020_TrainingData/input_data_3channels/'\n",
    "output_folder = '/kaggle/working/BraTS2020_TrainingData/input_data_128/'\n",
    "\n",
    "Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.75, .25), group_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_img(img_dir, img_list):\n",
    "    images=[]\n",
    "    for i, image_name in enumerate(img_list):    \n",
    "        if (image_name.split('.')[1] == 'npy'):\n",
    "            \n",
    "            image = np.load(img_dir+image_name)\n",
    "                      \n",
    "            images.append(image)\n",
    "    images = np.array(images)\n",
    "    \n",
    "    return(images)\n",
    "\n",
    "\n",
    "\n",
    "def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):\n",
    "\n",
    "    L = len(img_list)\n",
    "\n",
    "    #keras needs the generator infinite, so we will use while true  \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "                       \n",
    "            X = load_img(img_dir, img_list[batch_start:limit])\n",
    "            Y = load_img(mask_dir, mask_list[batch_start:limit])\n",
    "\n",
    "            yield (X,Y) #a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size\n",
    "            \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "train_img_dir = \"/kaggle/working/BraTS2020_TrainingData/input_data_128/train/images/\"\n",
    "train_mask_dir = \"/kaggle/working/BraTS2020_TrainingData/input_data_128/train/masks/\"\n",
    "train_img_list = sorted(os.listdir(train_img_dir))\n",
    "train_mask_list = sorted(os.listdir(train_mask_dir))\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "train_img_datagen = imageLoader(train_img_dir, train_img_list, train_mask_dir, train_mask_list, batch_size)\n",
    "\n",
    "img, msk = train_img_datagen.__next__()\n",
    "\n",
    "\n",
    "img_num = random.randint(0,img.shape[0]-1)\n",
    "test_img=img[img_num]\n",
    "test_mask=msk[img_num]\n",
    "test_mask=np.argmax(test_mask, axis=3)\n",
    "\n",
    "n_slice=random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_img[:,:,n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_img[:,:,n_slice, 1], cmap='gray')\n",
    "plt.title('Image t1ce')\n",
    "plt.subplot(223)\n",
    "plt.imshow(test_img[:,:,n_slice, 2], cmap='gray')\n",
    "plt.title('Image t2')\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv3D, MaxPooling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import MeanIoU\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "kernel_initializer =  'he_uniform' #Try others if you want\n",
    "\n",
    "\n",
    "################################################################\n",
    "def simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS, num_classes):\n",
    "#Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS))\n",
    "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
    "    s = inputs\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c1)\n",
    "    p1 = MaxPooling3D((2, 2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c2)\n",
    "    p2 = MaxPooling3D((2, 2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c3)\n",
    "    p3 = MaxPooling3D((2, 2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c4)\n",
    "    p4 = MaxPooling3D(pool_size=(2, 2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c5)\n",
    "    \n",
    "    #Expansive path \n",
    "    u6 = Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv3DTranspose(16, (2, 2, 2), strides=(2, 2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c9)\n",
    "     \n",
    "    outputs = Conv3D(num_classes, (1, 1, 1), activation='softmax')(c9)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    #compile model outside of this function to make it flexible. \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "#Test if everything is working ok. \n",
    "model = simple_unet_model(128, 128, 128, 3, 4)\n",
    "print(model.input_shape)\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "\n",
    "\n",
    "train_img_dir = \"/kaggle/working/BraTS2020_TrainingData/input_data_128/train/images/\"\n",
    "train_mask_dir = \"/kaggle/working/BraTS2020_TrainingData/input_data_128/train/masks/\"\n",
    "\n",
    "img_list = sorted(os.listdir(train_img_dir))\n",
    "msk_list = sorted(os.listdir(train_mask_dir))\n",
    "\n",
    "num_images = len(os.listdir(train_img_dir))\n",
    "\n",
    "img_num = random.randint(0,num_images-1)\n",
    "test_img = np.load(train_img_dir+img_list[img_num])\n",
    "test_mask = np.load(train_mask_dir+msk_list[img_num])\n",
    "test_mask = np.argmax(test_mask, axis=3)\n",
    "\n",
    "n_slice=random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_img[:,:,n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_img[:,:,n_slice, 1], cmap='gray')\n",
    "plt.title('Image t1ce')\n",
    "plt.subplot(223)\n",
    "plt.imshow(test_img[:,:,n_slice, 2], cmap='gray')\n",
    "plt.title('Image t2')\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = \"/kaggle/working/BraTS2020_TrainingData/input_data_128/train/images/\"\n",
    "train_mask_dir = \"/kaggle/working/BraTS2020_TrainingData/input_data_128/train/masks/\"\n",
    "\n",
    "val_img_dir = \"/kaggle/working/BraTS2020_TrainingData/input_data_128/val/images/\"\n",
    "val_mask_dir = \"/kaggle/working/BraTS2020_TrainingData/input_data_128/val/masks/\"\n",
    "\n",
    "train_img_list = sorted(os.listdir(train_img_dir))\n",
    "train_mask_list = sorted(os.listdir(train_mask_dir))\n",
    "\n",
    "val_img_list = sorted(os.listdir(val_img_dir))\n",
    "val_mask_list = sorted(os.listdir(val_mask_dir))\n",
    "\n",
    "\n",
    "########################################################################\n",
    "batch_size = 2\n",
    "\n",
    "train_img_datagen = imageLoader(train_img_dir, train_img_list, \n",
    "                                train_mask_dir, train_mask_list, batch_size)\n",
    "\n",
    "val_img_datagen = imageLoader(val_img_dir, val_img_list, \n",
    "                                val_mask_dir, val_mask_list, batch_size)\n",
    "\n",
    "#Verify generator.... In python 3 next() is renamed as __next__()\n",
    "img, msk = train_img_datagen.__next__()\n",
    "\n",
    "img_num = random.randint(0,img.shape[0]-1)\n",
    "test_img = img[img_num]\n",
    "test_mask = msk[img_num]\n",
    "test_mask = np.argmax(test_mask, axis=3)\n",
    "\n",
    "n_slice=random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_img[:,:,n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_img[:,:,n_slice, 1], cmap='gray')\n",
    "plt.title('Image t1ce')\n",
    "plt.subplot(223)\n",
    "plt.imshow(test_img[:,:,n_slice, 2], cmap='gray')\n",
    "plt.title('Image t2')\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation_models_3D\n",
    "import segmentation_models_3D as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define loss, metrics and optimizer to be used for training\n",
    "wt0, wt1, wt2, wt3 = 0.25,0.25,0.25,0.25\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=np.array([wt0, wt1, wt2, wt3])) \n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "metrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5)]\n",
    "\n",
    "LR = 0.0001\n",
    "optim = keras.optimizers.Adam(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model \n",
    "\n",
    "steps_per_epoch = len(train_img_list)//batch_size\n",
    "val_steps_per_epoch = len(val_img_list)//batch_size\n",
    "\n",
    "\n",
    "model = simple_unet_model(IMG_HEIGHT=128, \n",
    "                          IMG_WIDTH=128, \n",
    "                          IMG_DEPTH=128, \n",
    "                          IMG_CHANNELS=3, \n",
    "                          num_classes=4)\n",
    "\n",
    "model.compile(optimizer = optim, loss=total_loss, metrics=metrics)\n",
    "print(model.summary())\n",
    "\n",
    "print(model.input_shape)\n",
    "print(model.output_shape)\n",
    "\n",
    "history=model.fit(train_img_datagen,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=val_img_datagen,\n",
    "          validation_steps=val_steps_per_epoch,\n",
    "          )\n",
    "\n",
    "model.save('brats_3d.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation IoU and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# my_model = load_model('/kaggle/working/brats_3d.hdf5', custom_objects={'dice_loss_plus_1focal_loss': total_loss})\n",
    "\n",
    "my_model = load_model('/kaggle/working/brats_3d.hdf5', custom_objects={'dice_loss_plus_1focal_loss': total_loss,\n",
    "                    'iou_score':sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "\n",
    "#Now all set to continue the training process. \n",
    "history2=my_model.fit(train_img_datagen,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=val_img_datagen,\n",
    "          validation_steps=val_steps_per_epoch,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = load_model('/kaggle/working/brats_3d.hdf5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import MeanIoU\n",
    "\n",
    "abtch_size = 8\n",
    "test_img_datagen = imageLoader(val_img_dir, val_img_list, val_mask_dir,\n",
    "                              val_mask_list, batch_size)\n",
    "\n",
    "test_image_batch, test_mask_batch = test_img_datagen.__next__()\n",
    "\n",
    "test_mask_batch_argmax = np.argmax(test_mask_batch, axis=4)\n",
    "test_pred_batch = my_model.predict(test_image_batch)\n",
    "test_pred_batch_argmax = np.argmax(test_pred_batch, axis=4)\n",
    "\n",
    "n_classes = 4\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "\n",
    "img_num = 76\n",
    "\n",
    "test_img = np.load(\"/kaggle/working/BraTS2020_TrainingData/input_data_128/val/images/image_\"+str(img_num)+\".npy\")\n",
    "\n",
    "test_mask = np.load(\"/kaggle/working/BraTS2020_TrainingData/input_data_128/val/masks/mask_\"+str(img_num)+\".npy\")\n",
    "test_mask_argmax=np.argmax(test_mask, axis=3)\n",
    "\n",
    "test_img_input = np.expand_dims(test_img, axis=0)\n",
    "test_prediction = my_model.predict(test_img_input)\n",
    "test_prediction_argmax=np.argmax(test_prediction, axis=4)[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "#n_slice=random.randint(0, test_prediction_argmax.shape[2])\n",
    "n_slice = 55\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,n_slice,1], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(test_mask_argmax[:,:,n_slice])\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(test_prediction_argmax[:,:, n_slice])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
